{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEND - Authenticate\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Authenticate\n",
    "Authenticates your credentials and creates a client.\n",
    "'''\n",
    "endpoint = \"https://lab3-albertregus.cognitiveservices.azure.com/\"\n",
    "vision_key = \"570a3afbac67498ab7a45c74ec317fa9\"\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(vision_key))\n",
    "'''\n",
    "END - Authenticate\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problema 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. a) calitatea procesului de recunoastere a textului, atat la nivel de caracter, cat si la nivel de cuvant prin folosirea unei metrici de distanta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ComputerVisionOcrErrorException",
     "evalue": "Operation returned an invalid status code 'PermissionDenied'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mComputerVisionOcrErrorException\u001b[0m           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages/test2.jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# img = open(\"images/firefox.png\", \"rb\")\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m read_response \u001b[38;5;241m=\u001b[39m \u001b[43mcomputervision_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_in_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrinted\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m operation_id \u001b[38;5;241m=\u001b[39m read_response\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOperation-Location\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/azure/cognitiveservices/vision/computervision/operations/_computer_vision_client_operations.py:1709\u001b[0m, in \u001b[0;36mComputerVisionClientOperationsMixin.read_in_stream\u001b[0;34m(self, image, language, pages, model_version, reading_order, custom_headers, raw, callback, **operation_config)\u001b[0m\n\u001b[1;32m   1706\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(request, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moperation_config)\n\u001b[1;32m   1708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m202\u001b[39m]:\n\u001b[0;32m-> 1709\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m models\u001b[38;5;241m.\u001b[39mComputerVisionOcrErrorException(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize, response)\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raw:\n\u001b[1;32m   1712\u001b[0m     client_raw_response \u001b[38;5;241m=\u001b[39m ClientRawResponse(\u001b[38;5;28;01mNone\u001b[39;00m, response)\n",
      "\u001b[0;31mComputerVisionOcrErrorException\u001b[0m: Operation returned an invalid status code 'PermissionDenied'"
     ]
    }
   ],
   "source": [
    "# img = open(\"test1.png\", \"rb\")\n",
    "img = open(\"images/test2.jpeg\", \"rb\")\n",
    "# img = open(\"images/firefox.png\", \"rb\")\n",
    "\n",
    "read_response = computervision_client.read_in_stream(\n",
    "    image=img,\n",
    "    mode=\"Printed\",\n",
    "    raw=True\n",
    ")\n",
    "\n",
    "operation_id = read_response.headers['Operation-Location'].split('/')[-1]\n",
    "while True:\n",
    "    read_result = computervision_client.get_read_result(operation_id)\n",
    "    if read_result.status not in ['notStarted', 'running']:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "result = []\n",
    "if read_result.status == OperationStatusCodes.succeeded:\n",
    "    for text_result in read_result.analyze_result.read_results:\n",
    "        for line in text_result.lines:\n",
    "            # print(line.text)\n",
    "            result.append(line.text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# groundTruth = [\"Google Cloud\", \"Platform\"]\n",
    "groundTruth = [\"Succes in rezolvarea\", \"tEMELOR la\", \"LABORAtoaree de\", \"Inteligenta Artificiala!\"]\n",
    "# groundTruth = [\"Firefox\"]\n",
    "\n",
    "noOfCorrectLines = sum(i == j for i, j in zip(result, groundTruth))\n",
    "print(noOfCorrectLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text = \"Success in rezolvarea tEMELOR la LABORA toarele de Inteligenta Artificiala!\";\n",
    "\n",
    "# original_text = \"Firefox\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- calitatea procesului de recunoastere a textului folosind distanta Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lucces in resolvarea TEMELOR la LABORA toarele de Inteligenta Artificial√†!\n",
      "Distanta Levenshtein:  5\n"
     ]
    }
   ],
   "source": [
    "import editdistance\n",
    "\n",
    "def ocr_quality(original_text, ocr_output):\n",
    "    distance = editdistance.eval(original_text, ocr_output)\n",
    "    return distance\n",
    "\n",
    "ocr_text = ' '.join(result)\n",
    "print(ocr_text)\n",
    "\n",
    "distance = ocr_quality(original_text, ocr_text)\n",
    "print(\"Distanta Levenshtein: \", distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- calitatea procesului de recunoastere a textului folosing distanta Hamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stringurile trebuie sa aiba aceeasi lungime\n"
     ]
    }
   ],
   "source": [
    "def hamming_distance(s1, s2):\n",
    "\n",
    "    if len(s1) != len(s2):\n",
    "        raise ValueError(\"Stringurile trebuie sa aiba aceeasi lungime\")\n",
    "    \n",
    "    return sum(ch1 != ch2 for ch1, ch2 in zip(s1, s2))\n",
    "\n",
    "ocr_text = ' '.join(result)\n",
    "\n",
    "try:\n",
    "    distance = hamming_distance(original_text, ocr_text)\n",
    "    print(\"Distanta Hamming: \", distance)\n",
    "except ValueError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- calitatea procesului de recunoastere a textului folosing distanta Jaro-Winkler <br>\n",
    "0 - stringurile sunt total diferite <br>\n",
    "1 - stringurile sunt la fel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distanta Jaro-Winkler:  0.8654223237321829\n"
     ]
    }
   ],
   "source": [
    "import jellyfish\n",
    "\n",
    "ocr_text = ' '.join(result)\n",
    "\n",
    "jaro_winkler_distance = jellyfish.jaro_winkler_similarity(original_text, ocr_text)\n",
    "\n",
    "print(\"Distanta Jaro-Winkler: \", jaro_winkler_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) calitatea localizarii corecte a textului in imagine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/albert/.local/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'level': [1, 2, 3, 4, 5, 5], 'page_num': [1, 1, 1, 1, 1, 1], 'block_num': [0, 1, 1, 1, 1, 1], 'par_num': [0, 0, 1, 1, 1, 1], 'line_num': [0, 0, 0, 1, 1, 1], 'word_num': [0, 0, 0, 0, 1, 2], 'left': [0, 32, 32, 32, 32, 128], 'top': [0, 41, 41, 41, 41, 65], 'width': [334, 229, 229, 229, 78, 133], 'height': [153, 81, 81, 81, 81, 32], 'conf': [-1, -1, -1, -1, 43, 96], 'text': ['', '', '', '', '*', 'Firefox']}\n",
      "['', '', '', '', '*', 'Firefox'] [-1, -1, -1, -1, 43, 96]\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"images/firefox.png\")\n",
    "\n",
    "if image is not None:\n",
    "    cv2.imshow(\"Image\", cv2.resize(image, (800, 600)))\n",
    "    cv2.waitKey(0)  \n",
    "    cv2.destroyAllWindows() \n",
    "else:\n",
    "    print(\"Image not found or cannot be read.\")\n",
    "\n",
    "rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "results = pytesseract.image_to_data(rgb, output_type=Output.DICT)\n",
    "\n",
    "print(results)\n",
    "print(results[\"text\"], results[\"conf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence: 96\n",
      "Text: Firefox\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(results[\"text\"])):\n",
    "\t\n",
    "\tx = results[\"left\"][i]\n",
    "\ty = results[\"top\"][i]\n",
    "\tw = results[\"width\"][i]\n",
    "\th = results[\"height\"][i]\n",
    "\n",
    "\ttext = results[\"text\"][i]   # extrage textul \n",
    "\tconf = int(results[\"conf\"][i])  # nivelul de recunoastere\n",
    "\n",
    "\tif conf >= 50:\n",
    "\n",
    "\t\tprint(\"Confidence: {}\".format(conf))\n",
    "\t\tprint(\"Text: {}\".format(text))\n",
    "\t\tprint(\"\")\n",
    "\n",
    "\t\ttext = \"\".join([c if ord(c) < 128 else \"\" for c in text]).strip()\n",
    "\t\tcv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 1)\n",
    "\t\tcv2.putText(image, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) posibilitati de imbunatatire a recunoasterii textului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"images/firefox.png\")\n",
    "rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "results1 = pytesseract.image_to_data(rgb, output_type=Output.DICT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- utilizand Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "results2 = pytesseract.image_to_data(blurred_image, output_type=Output.DICT)\n",
    "\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Blurred Image', blurred_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Mucee! a Ae solvate  CTEMELOR fa.    APA GORA Ae 2 e : ay         \n",
      "    hee d fe sobvarea  PEMELOR 4a    AA GORA tone af    \n"
     ]
    }
   ],
   "source": [
    "ocr_text = ' '.join(results2[\"text\"])\n",
    "text = ' '.join(results1[\"text\"])\n",
    "\n",
    "print(text)\n",
    "print(ocr_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- utilizand Median Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blurred_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m results2 \u001b[38;5;241m=\u001b[39m pytesseract\u001b[38;5;241m.\u001b[39mimage_to_data(median_blurred_image, output_type\u001b[38;5;241m=\u001b[39mOutput\u001b[38;5;241m.\u001b[39mDICT)\n\u001b[1;32m      4\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOriginal Image\u001b[39m\u001b[38;5;124m'\u001b[39m, image)\n\u001b[0;32m----> 5\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlurred Image\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mblurred_image\u001b[49m)\n\u001b[1;32m      6\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      7\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'blurred_image' is not defined"
     ]
    }
   ],
   "source": [
    "median_blurred_image = cv2.medianBlur(image, 3)\n",
    "results2 = pytesseract.image_to_data(median_blurred_image, output_type=Output.DICT)\n",
    "\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Blurred Image', blurred_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Mucee! a Ae solvate  CTEMELOR fa.    APA GORA Ae 2 e : ay         \n",
      "    Zz CceA im fie solvareeg  tEMELOR Ae    AA GORA oe s    \n"
     ]
    }
   ],
   "source": [
    "ocr_text = ' '.join(results2[\"text\"])\n",
    "text = ' '.join(results1[\"text\"])\n",
    "\n",
    "print(text)\n",
    "print(ocr_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- folosind grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "results2 = pytesseract.image_to_data(grayscale_image, output_type=Output.DICT)\n",
    "\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Blurred Image', blurred_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Mucee! a Ae solvate  CTEMELOR fa.    APA GORA Ae 2 e : ay         \n",
      "    Doan Si fe sobvareg  PEMELOR 4a.    LAGORA ten pele = of    \n"
     ]
    }
   ],
   "source": [
    "ocr_text = ' '.join(results2[\"text\"])\n",
    "text = ' '.join(results1[\"text\"])\n",
    "\n",
    "print(text)\n",
    "print(ocr_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
